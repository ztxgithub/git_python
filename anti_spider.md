# python 反爬虫
 
## pyhton 爬虫基本概念

```shell

    1.爬虫
        自动获取网站数据的程序, 关键是批量的获取, 定时定量的从网站上抓取数据
        
    2.反爬虫
        使用技术手段防止爬虫程序的方法
        
    3.误伤
        反爬虫技术将普通用户识别为爬虫, 如果误伤过高, 效果再好也不能用。
        
        例如 禁止ip,这种方法实际不太可取, 
                原因1:例如一个公司或则学校, 对外的基本上是一个ip,如果禁掉这个 ip, 
                      则会导致公司正常访问受影响
                      
                原因2：如果采用DHCP分配的话, 会产生动态的ip
                
    4.成本
        爬虫和反爬虫都需要人力和机器成本
        
    5.拦截
        成功拦截爬虫, 一般拦截率越高, 误伤率也越高
```

## 反爬虫的目的

```shell
    1.防止初级爬虫
        初级爬虫简单粗暴, 不管服务器压力, 容易弄挂网站, 某个网站 80%的 PV 都是爬虫, 这样会导致
        增加服务器的压力
        
    2.数据保护
        搭建了一个网站,有大量的有价值的数据,其他公司需要大量的数据, 这时候得做好有价值数据的
        保护
        
    3.防止失控的爬虫
        由于某些情况下, 忘记或则无法关闭的爬虫, 需要对这类爬虫进行禁止
```

## 爬虫与反爬虫的对抗过程

```shell
                    爬虫端                                          网站(反爬虫端)
   1.对网站感兴趣,分析网络请求,用scrapy框架爬取数据    ----------->    2.监控发现某个时间段访问徒增,ip相同,
                                                                user-ageent 都是python, 直接限制
                                                                访问(不能封ip)
   3.将User-agent 模拟为浏览器(firefox),           ---------->    4.发现ip变化, 直接要求登录才能访问
     同时获取ip代理       
     
   5.注册账号, 每次请求带cookies或者token            --------->     6.健全账号体系, 即规范化访问权限和范围
                                                                  例如 A 只能访问好友的信息
   7.注册多个账号, 多个账号联合爬取                   --------->     8.请求过于频繁, 进一步增强ip访问频率的
                                                                  限制
   9.模拟人请求的习惯,限制请求速度                    --------->     10.弹出验证码,填写验证码
   11.通过各种手段识别验证码                         --------->     12.增加动态网站,数据通过js动态加载,增加
                                                                   网络分析复杂度, 发现大量请求
                                                                   
                                                                   当发现只请求html页面,不请求其他资源(css,js),
                                                                   可以判断是爬虫
                                                                   
   13.通过selenium和phantomjs完全模拟浏览器操作       --------->    14.成本太高,放弃  
      最终拿到的是浏览器看到的html效果     
   
   
   知识点:
         1.selenium 自动化操作浏览器  
         2.phantomjs 不界面话浏览器                
   
```
